import streamlit as st
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# ================== Cáº¤U HÃŒNH TRANG ==================
st.set_page_config(
    page_title="PhÃ¢n loáº¡i bá»‡nh tiá»ƒu Ä‘Æ°á»ng",
    page_icon="ğŸ©º",
    layout="wide"
)

st.title("ğŸ©º PHÃ‚N LOáº I Bá»†NH TIá»‚U ÄÆ¯á»œNG Báº°NG CÃ‚Y QUYáº¾T Äá»ŠNH")
st.caption("MÃ´ hÃ¬nh Decision Tree â€“ dá»¯ liá»‡u giáº£ láº­p Pima Diabetes")
st.markdown("---")

# ================== Táº O Dá»® LIá»†U ==================
st.header("1ï¸âƒ£ Táº¡o dá»¯ liá»‡u giáº£ láº­p")

np.random.seed(1)
n_samples = 768

pima = pd.DataFrame({
    "pregnant": np.random.randint(0, 15, n_samples),
    "glucose": np.random.randint(70, 200, n_samples),
    "bp": np.random.randint(40, 120, n_samples),
    "skin": np.random.randint(0, 100, n_samples),
    "insulin": np.random.randint(0, 300, n_samples),
    "bmi": np.round(np.random.uniform(18, 50, n_samples), 1),
    "pedigree": np.round(np.random.uniform(0.1, 2.5, n_samples), 3),
    "age": np.random.randint(21, 70, n_samples)
})

label = []
for i in range(n_samples):
    risk = 0
    if pima.loc[i, "glucose"] > 140: risk += 1
    if pima.loc[i, "bmi"] > 30: risk += 1
    if pima.loc[i, "age"] > 45: risk += 1
    label.append(
        1 if (risk >= 2 and np.random.rand() > 0.25)
        else 1 if (risk < 2 and np.random.rand() > 0.8)
        else 0
    )

pima["label"] = label

col1, col2 = st.columns(2)
col1.metric("Sá»‘ máº«u", pima.shape[0])
col2.metric("Sá»‘ thuá»™c tÃ­nh", pima.shape[1] - 1)

with st.expander("ğŸ“Š Xem 5 dÃ²ng dá»¯ liá»‡u Ä‘áº§u tiÃªn"):
    st.dataframe(pima.head(), use_container_width=True)

# ================== PHÃ‚N Bá» NHÃƒN ==================
st.header("2ï¸âƒ£ PhÃ¢n bá»‘ nhÃ£n")

label_counts = pima["label"].value_counts()
st.dataframe(label_counts.to_frame("Sá»‘ lÆ°á»£ng"))

fig1, ax1 = plt.subplots()
label_counts.plot(
    kind="bar",
    xlabel="NhÃ£n (0: KhÃ´ng bá»‡nh, 1: Bá»‹ bá»‡nh)",
    ylabel="Sá»‘ máº«u",
    legend=False,
    ax=ax1
)
st.pyplot(fig1)

# ================== CHá»ŒN THUá»˜C TÃNH ==================
st.header("3ï¸âƒ£ Thuá»™c tÃ­nh & táº­p dá»¯ liá»‡u")

feature_cols = ["pregnant", "insulin", "bmi", "age", "glucose", "bp", "pedigree"]
X = pima[feature_cols]
y = pima["label"]

st.write("**CÃ¡c thuá»™c tÃ­nh sá»­ dá»¥ng:**")
st.write(", ".join(feature_cols))

# ================== TRAIN / TEST ==================
st.header("4ï¸âƒ£ Chia dá»¯ liá»‡u & huáº¥n luyá»‡n mÃ´ hÃ¬nh")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=1
)

col1, col2 = st.columns(2)
col1.metric("Train", X_train.shape[0])
col2.metric("Test", X_test.shape[0])

clf = DecisionTreeClassifier(
    criterion="entropy",
    max_depth=3,
    random_state=1
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# ================== ÄÃNH GIÃ ==================
st.header("5ï¸âƒ£ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh")

col1, col2, col3, col4 = st.columns(4)
col1.metric("Criterion", clf.criterion)
col2.metric("Max depth", clf.max_depth)
col3.metric("Äá»™ sÃ¢u thá»±c táº¿", clf.get_depth())
col4.metric("Sá»‘ nÃºt lÃ¡", clf.get_n_leaves())

st.success(f"ğŸ¯ Accuracy: {accuracy_score(y_test, y_pred):.2%}")

with st.expander("ğŸ“Œ Confusion Matrix"):
    cm_df = pd.DataFrame(
        confusion_matrix(y_test, y_pred),
        columns=["Dá»± Ä‘oÃ¡n 0", "Dá»± Ä‘oÃ¡n 1"],
        index=["Thá»±c táº¿ 0", "Thá»±c táº¿ 1"]
    )
    st.dataframe(cm_df)

with st.expander("ğŸ“Œ Classification Report"):
    st.text(classification_report(y_test, y_pred, target_names=["KhÃ´ng bá»‡nh", "Bá»‹ bá»‡nh"]))

# ================== SO SÃNH ==================
st.header("6ï¸âƒ£ So sÃ¡nh nhÃ£n thá»±c táº¿ & dá»± Ä‘oÃ¡n")
compare_df = pd.DataFrame({
    "Thá»±c táº¿": y_test.values[:10],
    "Dá»± Ä‘oÃ¡n": y_pred[:10]
})
st.dataframe(compare_df)

# ================== CÃ‚Y QUYáº¾T Äá»ŠNH ==================
st.header("7ï¸âƒ£ Trá»±c quan hÃ³a cÃ¢y quyáº¿t Ä‘á»‹nh")

fig2, ax2 = plt.subplots(figsize=(22, 10))
plot_tree(
    clf,
    feature_names=feature_cols,
    class_names=["KhÃ´ng bá»‡nh (0)", "Bá»‹ bá»‡nh (1)"],
    filled=True,
    rounded=True,
    fontsize=9,
    ax=ax2
)
st.pyplot(fig2)

# ================== Dá»° ÄOÃN MáºªU ==================
st.header("8ï¸âƒ£ Dá»± Ä‘oÃ¡n cho bá»‡nh nhÃ¢n máº«u")

new_patient = pd.DataFrame({
    "pregnant": [2],
    "insulin": [120],
    "bmi": [32.5],
    "age": [45],
    "glucose": [150],
    "bp": [85],
    "pedigree": [0.6]
})

prediction = clf.predict(new_patient)
probability = clf.predict_proba(new_patient)

st.dataframe(new_patient)

if prediction[0] == 1:
    st.error("âŒ Káº¾T LUáº¬N: Bá»Š Bá»†NH TIá»‚U ÄÆ¯á»œNG")
else:
    st.success("âœ… Káº¾T LUáº¬N: KHÃ”NG Bá»Š Bá»†NH TIá»‚U ÄÆ¯á»œNG")

st.write("**XÃ¡c suáº¥t:**")
st.write(f"- KhÃ´ng bá»‡nh: {probability[0][0]:.2%}")
st.write(f"- Bá»‹ bá»‡nh  : {probability[0][1]:.2%}")
